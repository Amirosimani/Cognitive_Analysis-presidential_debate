{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Video Processing **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vidcap = cv2.VideoCapture('debate_sample.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "success,image = vidcap.read()\n",
    "count = 0\n",
    "success = True\n",
    "while success:\n",
    "  success,image = vidcap.read()\n",
    "  cv2.imwrite(\"images/frame%d.jpg\" % count, image)     # save frame as JPEG file\n",
    "  if cv2.waitKey(10) == 27:                     # exit if Escape is hit\n",
    "    break\n",
    "  count += 1\n",
    "\n",
    "# Adding a wait time for each frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# need to add time interval\n",
    "# saving on S3 maybe?\n",
    "\n",
    "#### https://github.com/Microsoft/Cognitive-Face-Python/blob/master/cognitive_face/face.py ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Detecting gender in the images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cognitive_face as CF\n",
    "from cognitive_face import util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CF.Key.set('2ed7c5847ac640f6b0a404c72d0b96f2') #set the key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def detect(image, face_id=True, landmarks=False, faceRectangle= False, attributes='gender'):\n",
    "    \n",
    "    url = 'detect'\n",
    "    headers, data, json = util.parse_image(image)\n",
    "    params = {\n",
    "        'returnFaceId': face_id and 'true' or 'false',\n",
    "        'returnFaceLandmarks': landmarks and 'true' or 'false',\n",
    "        'returnFaceAttributes': attributes,\n",
    "    }\n",
    "\n",
    "    return util.request('POST', url, headers=headers, params=params, json=json,\n",
    "                        data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image = '/Users/Amiros/GitHub/debate/images/frame10.jpg' #puting the image location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'faceAttributes': {'gender': 'male'},\n",
       "  'faceId': '29ba22bf-2284-4cb0-a0a6-771ce0a47f1a',\n",
       "  'faceRectangle': {'height': 140, 'left': 212, 'top': 110, 'width': 140}},\n",
       " {'faceAttributes': {'gender': 'female'},\n",
       "  'faceId': 'a1d34384-b6c2-404d-90eb-840815d61d64',\n",
       "  'faceRectangle': {'height': 137, 'left': 640, 'top': 106, 'width': 137}}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detect(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'faceAttributes': {'gender': 'male'},\n",
       "  'faceId': '0f3399c9-7416-4203-b101-c42b5c1fbe3f',\n",
       "  'faceRectangle': {'height': 141, 'left': 212, 'top': 110, 'width': 141}},\n",
       " {'faceAttributes': {'gender': 'female'},\n",
       "  'faceId': '25b2310b-ba4c-4d9f-a177-39ec1fb7fcf7',\n",
       "  'faceRectangle': {'height': 136, 'left': 639, 'top': 107, 'width': 136}}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image2 = '/Users/Amiros/GitHub/debate/images/frame11.jpg' #puting the image location\n",
    "detect(image2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# the idea is to go through the whole fodler,\n",
    "# put everything in a dataframe,\n",
    "# and group them by gender\n",
    "\n",
    "## or I can use an album of H&T photos and then assign them to the respective ones\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 3. Grouping**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def group(face_ids):\n",
    "    \"\"\"Divide candidate faces into groups based on face similarity.\n",
    "    Args:\n",
    "        face_ids: An array of candidate `face_id`s created by `face.detect`.\n",
    "            The maximum is 1000 faces.\n",
    "    Returns:\n",
    "        one or more groups of similar faces (ranked by group size) and a\n",
    "        messyGroup.\n",
    "    \"\"\"\n",
    "    url = 'group'\n",
    "    json = {\n",
    "        'faceIds': face_ids,\n",
    "    }\n",
    "\n",
    "    return util.request('POST', url, json=json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idLists = ('0f3399c9-7416-4203-b101-c42b5c1fbe3f', '25b2310b-ba4c-4d9f-a177-39ec1fb7fcf7', 'a1d34384-b6c2-404d-90eb-840815d61d64', '29ba22bf-2284-4cb0-a0a6-771ce0a47f1a') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "group1 = group(idLists)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Emotion of groups **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'groups': [['0f3399c9-7416-4203-b101-c42b5c1fbe3f',\n",
       "   '29ba22bf-2284-4cb0-a0a6-771ce0a47f1a'],\n",
       "  ['25b2310b-ba4c-4d9f-a177-39ec1fb7fcf7',\n",
       "   'a1d34384-b6c2-404d-90eb-840815d61d64']],\n",
       " 'messyGroup': []}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
